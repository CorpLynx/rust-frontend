use anyhow::{Context, Result};
use crate::backend::BackendClient;
use crate::commands::{Command, display_help};
use crate::error::{ErrorDisplay, ErrorContext};
use crate::streaming::StreamingHandler;
use crate::terminal::Terminal;
use crate::config::AppConfig;
use crate::conversation::{ChatMessage, Conversation, ConversationManager};
use crate::update::{UpdateManager, UpdateStatus};
use std::sync::Arc;

/// CLI application state and REPL loop
pub struct CliApp {
    #[allow(dead_code)]
    config: AppConfig,
    conversation: Conversation,
    conversation_manager: ConversationManager,
    backend_client: BackendClient,
    terminal: Terminal,
    running: bool,
    model: String,
    backend_url: String,
    timeout_seconds: u64,
}

impl CliApp {
    /// Create a new CLI application instance
    ///
    /// Implements configuration override precedence (Requirement 4.5):
    /// CLI arguments take precedence over config file values.
    ///
    /// # Arguments
    /// * `config` - Application configuration loaded from config.toml
    /// * `backend_url` - Optional backend URL override from CLI arguments
    /// * `model` - Optional model name override from CLI arguments
    ///
    /// # Requirements
    /// * 4.1: Load configuration from config.toml file
    /// * 4.2: Use configured Ollama URL for all backend requests
    /// * 4.3: Use configured model for generating responses
    /// * 4.4: Use default values when configuration is missing/invalid
    /// * 4.5: CLI arguments override config file values
    pub fn new(
        config: AppConfig,
        backend_url: Option<String>,
        model: Option<String>,
    ) -> Result<Self> {
        // Implement configuration override precedence (Requirement 4.5)
        // CLI arguments take precedence over config file values
        let url = backend_url.unwrap_or_else(|| config.backend.ollama_url.clone());
        let model_name = model.unwrap_or_else(|| "llama2".to_string());

        let backend_client = BackendClient::new(url.clone(), config.backend.timeout_seconds)
            .context("Failed to create backend client")?;

        let terminal = Terminal::new().context("Failed to create terminal")?;

        let conversation_manager = ConversationManager::new();
        let conversation = Conversation::with_timestamp_name(Some(model_name.clone()));

        Ok(Self {
            timeout_seconds: config.backend.timeout_seconds,
            config,
            conversation,
            conversation_manager,
            backend_client,
            terminal,
            running: true,
            model: model_name,
            backend_url: url,
        })
    }

    #[cfg(test)]
    pub fn new_with_temp_dir(
        config: AppConfig,
        backend_url: Option<String>,
        model: Option<String>,
        temp_dir: &std::path::Path,
    ) -> Result<Self> {
        let url = backend_url.unwrap_or_else(|| config.backend.ollama_url.clone());
        let model_name = model.unwrap_or_else(|| "llama2".to_string());

        let backend_client = BackendClient::new(url.clone(), config.backend.timeout_seconds)
            .context("Failed to create backend client")?;

        let terminal = Terminal::new().context("Failed to create terminal")?;

        let conversation_manager = ConversationManager::with_directory(temp_dir);
        let conversation = Conversation::with_timestamp_name(Some(model_name.clone()));

        Ok(Self {
            timeout_seconds: config.backend.timeout_seconds,
            config,
            conversation,
            conversation_manager,
            backend_client,
            terminal,
            running: true,
            model: model_name,
            backend_url: url,
        })
    }

    /// Create a new CLI application instance with interactive model selection
    ///
    /// This method fetches available models from the backend and prompts the user
    /// to select one before starting the chat session.
    ///
    /// # Arguments
    /// * `config` - Application configuration loaded from config.toml
    /// * `backend_url` - Optional backend URL override from CLI arguments
    /// * `model` - Optional model name override from CLI arguments (skips selection if provided)
    pub async fn new_with_model_selection(
        config: AppConfig,
        backend_url: Option<String>,
        model: Option<String>,
    ) -> Result<Self> {
        let mut terminal = Terminal::new().context("Failed to create terminal")?;

        // Display ASCII art banner in green
        terminal.write("\n")?;
        terminal.write_green("   ________  ________  ________  ________  ________  ________  ________  ________  ________  ________ \n")?;
        terminal.write_green("  /        \\/        \\/        \\/        \\/        \\/        \\/    /   \\/        \\/    /   \\/        \\\n")?;
        terminal.write_green(" /         /         /         /         /         /        _/         /         /         /        _/\n")?;
        terminal.write_green("//      __/        _/         /         /        _//       //         /        _/         /-        / \n")?;
        terminal.write_green("\\\\_____/  \\____/___/\\________/\\__/__/__/\\________/ \\______/ \\___/____/\\________/\\________/\\________/  \n")?;
        terminal.write("\n")?;

        // If model is explicitly provided via CLI, skip selection
        if model.is_some() {
            return Self::new(config, backend_url, model);
        }

        let url = backend_url.unwrap_or_else(|| config.backend.ollama_url.clone());
        
        // Create a temporary backend client to fetch models
        let temp_client = BackendClient::new(url.clone(), config.backend.timeout_seconds)
            .context("Failed to create backend client")?;

        // Fetch available models
        terminal.write_info("Fetching available models...")?;
        
        let models = match temp_client.fetch_models().await {
            Ok(models) if !models.is_empty() => models,
            Ok(_) => {
                terminal.write_error("No models found on the backend")?;
                anyhow::bail!("No models available");
            }
            Err(e) => {
                terminal.write_error(&format!("Failed to fetch models: {}", e))?;
                terminal.write_info("Using default model: llama2")?;
                return Self::new(config, Some(url), Some("llama2".to_string()));
            }
        };

        // Display available models
        terminal.write("\n")?;
        terminal.write_info("Available models:")?;
        for (i, model_name) in models.iter().enumerate() {
            terminal.write(&format!("  {}. {}", i + 1, model_name))?;
        }
        terminal.write("\n")?;

        // Prompt for selection
        let selected_model = loop {
            terminal.write("Select a model (enter number): ")?;
            
            match terminal.read_line() {
                Ok(input) => {
                    let input = input.trim();
                    
                    // Try to parse as number
                    if let Ok(num) = input.parse::<usize>() {
                        if num > 0 && num <= models.len() {
                            break models[num - 1].clone();
                        } else {
                            terminal.write_error(&format!(
                                "Invalid selection. Please enter a number between 1 and {}",
                                models.len()
                            ))?;
                        }
                    } else {
                        terminal.write_error("Please enter a valid number")?;
                    }
                }
                Err(e) => {
                    terminal.write_error(&format!("Failed to read input: {}", e))?;
                    anyhow::bail!("Failed to read model selection");
                }
            }
        };

        terminal.write("\n")?;
        terminal.write_info(&format!("Selected model: {}", selected_model))?;

        // Now create the app with the selected model
        Self::new(config, Some(url), Some(selected_model))
    }

    /// Get the backend URL being used by this CLI instance
    pub fn backend_url(&self) -> &str {
        &self.backend_url
    }

    /// Get the model being used by this CLI instance
    pub fn model(&self) -> &str {
        &self.model
    }

    /// Display welcome message
    fn display_welcome(&mut self) -> Result<()> {
        self.terminal.write("\n")?;
        self.terminal.write_info(&format!(
            "Prometheus CLI v{} - Terminal AI Chat",
            env!("CARGO_PKG_VERSION")
        ))?;
        self.terminal.write_info(&format!(
            "Connected to: {}",
            self.backend_client.base_url()
        ))?;
        self.terminal.write_info(&format!("Model: {}", self.model))?;
        self.terminal
            .write_info("Type /help for available commands")?;
        self.terminal.write("\n")?;
        Ok(())
    }

    /// Run the main REPL loop with signal handling
    ///
    /// This method implements signal handling for graceful shutdown:
    /// - SIGINT (Ctrl+C) at prompt: Save conversation and exit
    /// - SIGINT during streaming: Stop streaming, save partial response, return to prompt
    /// - SIGTERM: Save conversation and exit immediately
    ///
    /// # Requirements
    /// * 9.5: Handle SIGINT gracefully by saving conversation and exiting cleanly
    /// * 10.1: Stop streaming request when Ctrl+C is pressed during generation
    /// * 10.2: Save partial response to conversation when generation is stopped
    /// * 10.3: Display interruption message when generation is stopped
    /// * 10.4: Return to prompt for new input after stopping generation
    /// * 10.5: Exit application after saving conversation when Ctrl+C at prompt
    pub async fn run(&mut self) -> Result<()> {
        self.display_welcome()?;

        // Set up signal handlers
        let mut sigint = tokio::signal::unix::signal(tokio::signal::unix::SignalKind::interrupt())
            .context("Failed to set up SIGINT handler")?;
        let mut sigterm = tokio::signal::unix::signal(tokio::signal::unix::SignalKind::terminate())
            .context("Failed to set up SIGTERM handler")?;

        while self.running {
            // Display prompt
            self.terminal.write("> ")?;

            // Create a channel for reading input
            let (tx, mut rx) = tokio::sync::mpsc::channel(1);
            
            // Spawn a task to read input
            let terminal_clone = Terminal::new()?;
            tokio::spawn(async move {
                let mut term = terminal_clone;
                if let Ok(input) = term.read_line() {
                    let _ = tx.send(input).await;
                }
            });

            // Wait for either input or signal
            tokio::select! {
                // Handle SIGINT (Ctrl+C) at prompt
                _ = sigint.recv() => {
                    self.terminal.write("\n")?;
                    self.terminal.write_info("Received interrupt signal. Saving conversation and exiting...")?;
                    self.running = false;
                    break;
                }
                // Handle SIGTERM
                _ = sigterm.recv() => {
                    self.terminal.write("\n")?;
                    self.terminal.write_info("Received termination signal. Saving conversation and exiting...")?;
                    self.running = false;
                    break;
                }
                // Handle user input
                Some(input) = rx.recv() => {
                    // Handle empty input
                    if input.trim().is_empty() {
                        continue;
                    }

                    // Check if it's a command or a prompt
                    if input.starts_with('/') {
                        self.handle_command(&input).await?;
                    } else {
                        // Handle prompt with signal support during streaming
                        self.handle_prompt_with_signals(input, &mut sigint).await?;
                    }
                }
            }
        }

        self.shutdown().await
    }

    /// Handle a user prompt
    #[allow(dead_code)]
    async fn handle_prompt(&mut self, prompt: String) -> Result<()> {
        // Add user message to conversation
        let user_message = ChatMessage::new("user".to_string(), prompt.clone());
        self.conversation.add_message(user_message);

        // Display user prompt
        self.terminal.write_user_prompt(&prompt)?;

        // Show loading indicator
        self.terminal.show_spinner()?;

        // Create streaming handler
        let mut streaming_handler = StreamingHandler::new(Terminal::new()?);

        // Send prompt to backend with streaming
        let result = self
            .backend_client
            .send_prompt_streaming(&prompt, &self.model, |chunk| {
                streaming_handler.on_chunk(chunk)
            })
            .await;

        // Hide spinner
        self.terminal.hide_spinner()?;

        // Handle response or error
        match result {
            Ok(_response) => {
                // Finalize streaming (adds newline)
                let final_response = streaming_handler.finalize()?;

                // Add AI response to conversation
                let ai_message = ChatMessage::new("assistant".to_string(), final_response);
                self.conversation.add_message(ai_message);

                // Save conversation
                if let Err(e) = self.conversation_manager.save_conversation(&self.conversation) {
                    let mut error_display = ErrorDisplay::new(Terminal::new()?);
                    let context = ErrorContext::Filesystem {
                        operation: "save".to_string(),
                        path: "conversation".to_string(),
                    };
                    error_display.display_error_with_context(&e, context)?;
                }
            }
            Err(e) => {
                // Display error with appropriate context
                let mut error_display = ErrorDisplay::new(Terminal::new()?);
                let context = ErrorContext::Backend {
                    url: self.backend_url.clone(),
                    timeout_seconds: self.timeout_seconds,
                };
                error_display.display_error_with_context(&e, context)?;

                // Save partial response if any
                let partial = streaming_handler.buffer().to_string();
                if !partial.is_empty() {
                    // Add newline after partial response
                    self.terminal.write("\n")?;
                    
                    // Save partial response to conversation
                    let ai_message = ChatMessage::new("assistant".to_string(), partial);
                    self.conversation.add_message(ai_message);

                    // Try to save conversation with partial response
                    if let Err(save_err) = self
                        .conversation_manager
                        .save_conversation(&self.conversation)
                    {
                        let fs_context = ErrorContext::Filesystem {
                            operation: "save".to_string(),
                            path: "conversation".to_string(),
                        };
                        error_display.display_error_with_context(&save_err, fs_context)?;
                    }
                }
            }
        }

        Ok(())
    }

    /// Handle a user prompt with signal handling during streaming
    ///
    /// This method handles SIGINT (Ctrl+C) during streaming by stopping the request,
    /// saving the partial response, and returning to the prompt.
    ///
    /// # Requirements
    /// * 10.1: Stop streaming request when Ctrl+C is pressed
    /// * 10.2: Save partial response to conversation
    /// * 10.3: Display interruption message
    /// * 10.4: Return to prompt for new input
    async fn handle_prompt_with_signals(
        &mut self,
        prompt: String,
        sigint: &mut tokio::signal::unix::Signal,
    ) -> Result<()> {
        // Add user message to conversation
        let user_message = ChatMessage::new("user".to_string(), prompt.clone());
        self.conversation.add_message(user_message);

        // Display user prompt
        self.terminal.write_user_prompt(&prompt)?;

        // Show loading indicator
        self.terminal.show_spinner()?;

        // Create streaming handler with Arc<Mutex> for thread-safe access
        let streaming_handler = Arc::new(std::sync::Mutex::new(StreamingHandler::new(Terminal::new()?)));
        let streaming_handler_clone = Arc::clone(&streaming_handler);

        // Create a channel to signal cancellation
        let (cancel_tx, _cancel_rx) = tokio::sync::mpsc::channel::<()>(1);

        // Spawn the backend request in a separate task
        let backend_client = self.backend_client.clone();
        let model = self.model.clone();
        let request_task = tokio::spawn(async move {
            backend_client
                .send_prompt_streaming(&prompt, &model, |chunk| {
                    // Use std::sync::Mutex for synchronous access in callback
                    let mut handler = streaming_handler_clone.lock().unwrap();
                    handler.on_chunk(chunk)
                })
                .await
        });

        // Wait for either the request to complete or SIGINT
        let result = tokio::select! {
            // Request completed
            res = request_task => {
                match res {
                    Ok(backend_result) => backend_result,
                    Err(e) => Err(anyhow::anyhow!("Request task failed: {}", e)),
                }
            }
            // SIGINT received during streaming
            _ = sigint.recv() => {
                // Send cancellation signal
                let _ = cancel_tx.send(()).await;
                
                // Hide spinner
                self.terminal.hide_spinner()?;
                
                // Get partial response
                let handler = streaming_handler.lock().unwrap();
                let partial = handler.buffer().to_string();
                drop(handler);
                
                // Display interruption message
                self.terminal.write("\n")?;
                self.terminal.write_info("Response generation interrupted by user")?;
                
                // Save partial response if any
                if !partial.is_empty() {
                    let ai_message = ChatMessage::new("assistant".to_string(), partial);
                    self.conversation.add_message(ai_message);
                    
                    if let Err(e) = self.conversation_manager.save_conversation(&self.conversation) {
                        let mut error_display = ErrorDisplay::new(Terminal::new()?);
                        let context = ErrorContext::Filesystem {
                            operation: "save".to_string(),
                            path: "conversation".to_string(),
                        };
                        error_display.display_error_with_context(&e, context)?;
                    }
                }
                
                return Ok(());
            }
        };

        // Hide spinner
        self.terminal.hide_spinner()?;

        // Handle response or error
        match result {
            Ok(_response) => {
                // Finalize streaming (adds newline)
                let mut handler = streaming_handler.lock().unwrap();
                let final_response = handler.finalize()?;
                drop(handler);

                // Add AI response to conversation
                let ai_message = ChatMessage::new("assistant".to_string(), final_response);
                self.conversation.add_message(ai_message);

                // Save conversation
                if let Err(e) = self.conversation_manager.save_conversation(&self.conversation) {
                    let mut error_display = ErrorDisplay::new(Terminal::new()?);
                    let context = ErrorContext::Filesystem {
                        operation: "save".to_string(),
                        path: "conversation".to_string(),
                    };
                    error_display.display_error_with_context(&e, context)?;
                }
            }
            Err(e) => {
                // Display error with appropriate context
                let mut error_display = ErrorDisplay::new(Terminal::new()?);
                let context = ErrorContext::Backend {
                    url: self.backend_url.clone(),
                    timeout_seconds: self.timeout_seconds,
                };
                error_display.display_error_with_context(&e, context)?;

                // Save partial response if any
                let handler = streaming_handler.lock().unwrap();
                let partial = handler.buffer().to_string();
                drop(handler);

                if !partial.is_empty() {
                    // Add newline after partial response
                    self.terminal.write("\n")?;
                    
                    // Save partial response to conversation
                    let ai_message = ChatMessage::new("assistant".to_string(), partial);
                    self.conversation.add_message(ai_message);

                    // Try to save conversation with partial response
                    if let Err(save_err) = self
                        .conversation_manager
                        .save_conversation(&self.conversation)
                    {
                        let fs_context = ErrorContext::Filesystem {
                            operation: "save".to_string(),
                            path: "conversation".to_string(),
                        };
                        error_display.display_error_with_context(&save_err, fs_context)?;
                    }
                }
            }
        }

        Ok(())
    }

    /// Handle a special command
    async fn handle_command(&mut self, input: &str) -> Result<()> {
        let command = Command::parse(input);

        match command {
            Command::Exit | Command::Quit => {
                self.terminal.write_info("Saving conversation and exiting...")?;
                self.running = false;
            }
            Command::Clear => {
                self.terminal.clear_screen()?;
                self.display_welcome()?;
            }
            Command::New => {
                // Save current conversation
                self.conversation_manager
                    .save_conversation(&self.conversation)
                    .context("Failed to save current conversation")?;

                // Create new conversation
                self.conversation = Conversation::with_timestamp_name(Some(self.model.clone()));
                self.terminal.write_info("Started new conversation")?;
            }
            Command::Help => {
                let help_text = display_help();
                self.terminal.write(&help_text)?;
            }
            Command::Models => {
                self.terminal.write_info("Fetching available models...")?;
                match self.backend_client.fetch_models().await {
                    Ok(models) => {
                        self.terminal.write("\nAvailable models:\n")?;
                        for model in models {
                            self.terminal.write(&format!("  - {}\n", model))?;
                        }
                        self.terminal.write("\n")?;
                    }
                    Err(e) => {
                        let mut error_display = ErrorDisplay::new(Terminal::new()?);
                        let context = ErrorContext::Backend {
                            url: self.backend_url.clone(),
                            timeout_seconds: self.timeout_seconds,
                        };
                        error_display.display_error_with_context(&e, context)?;
                    }
                }
            }
            Command::Update => {
                self.handle_update().await?;
            }
            Command::UpdateCheck => {
                self.handle_update_check().await?;
            }
            Command::Unknown(cmd) => {
                self.terminal.write_error(&format!(
                    "Unknown command: /{}. Type /help for available commands",
                    cmd
                ))?;
            }
        }

        Ok(())
    }

    /// Handle the update check command
    /// 
    /// Checks for available updates without performing the update.
    /// Displays information about available updates or confirms the installation is up to date.
    /// 
    /// # Requirements
    /// * 2.1: Compare local git commit with remote repository
    /// * 2.2: Display number of commits behind and summary of changes
    /// * 2.3: Display message when installation is up to date
    /// * 2.4: Display error message when check operation fails
    async fn handle_update_check(&mut self) -> Result<()> {
        self.terminal.write_info("ðŸ” Checking for updates...")?;

        let manager = match UpdateManager::new() {
            Ok(m) => m,
            Err(e) => {
                self.terminal.write_error(&format!("Update check failed: {}", e))?;
                self.terminal.write_info("Troubleshooting tips:")?;
                self.terminal.write("  â€¢ Ensure Prometheus CLI was installed from source (git clone)")?;
                self.terminal.write("  â€¢ Check that git is installed and accessible")?;
                self.terminal.write("  â€¢ Verify the installation directory exists and is readable")?;
                return Ok(());
            }
        };

        if let Err(e) = manager.validate_installation() {
            self.terminal.write_error(&format!("Installation validation failed: {}", e))?;
            self.terminal.write_info("Troubleshooting tips:")?;
            self.terminal.write("  â€¢ Ensure you installed Prometheus CLI using the git-based installer")?;
            self.terminal.write("  â€¢ Manual installations or binary downloads cannot be updated automatically")?;
            self.terminal.write("  â€¢ Consider reinstalling from source: https://github.com/your-repo/prometheus")?;
            return Ok(());
        }

        match manager.check_for_updates() {
            Ok(UpdateStatus::UpToDate) => {
                self.terminal.write_info("âœ… Your installation is up to date!")?;
                self.terminal.write(&format!("   Installation directory: {}", manager.install_dir().display()))?;
                self.terminal.write(&format!("   Binary location: {}", manager.bin_dir().join(manager.binary_name()).display()))?;
            }
            Ok(UpdateStatus::UpdatesAvailable { commits_behind, changes }) => {
                self.terminal.write_info(&format!(
                    "ðŸ†• Updates available! {} commit(s) behind the latest version.",
                    commits_behind
                ))?;
                self.terminal.write("\nðŸ“‹ Recent changes:")?;
                
                // Format the changes nicely
                for line in changes.lines() {
                    if !line.trim().is_empty() {
                        self.terminal.write(&format!("   {}", line))?;
                    }
                }
                
                self.terminal.write("\nðŸ’¡ Run '/update' to install these updates.")?;
                self.terminal.write("   Note: The update process will require a few minutes to complete.")?;
            }
            Err(e) => {
                self.terminal.write_error(&format!("Update check failed: {}", e))?;
                self.terminal.write_info("Troubleshooting tips:")?;
                self.terminal.write("  â€¢ Check your internet connection")?;
                self.terminal.write("  â€¢ Ensure git credentials are configured if the repository requires authentication")?;
                self.terminal.write("  â€¢ Try running 'git fetch' manually in the installation directory")?;
                self.terminal.write(&format!("  â€¢ Installation directory: {}", manager.install_dir().display()))?;
            }
        }

        Ok(())
    }

    /// Handle the update command
    /// 
    /// Performs the actual update process: fetch, build, and install.
    /// Provides progress feedback and handles errors gracefully.
    /// 
    /// # Requirements
    /// * 1.1: Fetch latest changes from git repository
    /// * 1.2: Rebuild CLI binary using cargo
    /// * 1.3: Replace installed binary with new version
    /// * 1.4: Display success message with new version number
    /// * 1.5: Display clear error message and maintain existing installation on failure
    /// * 4.1-4.4: Display progress messages during update process
    async fn handle_update(&mut self) -> Result<()> {
        self.terminal.write_info("ðŸš€ Starting update process...")?;
        self.terminal.write("   This process will fetch the latest code, rebuild the binary, and install it.")?;
        self.terminal.write("   The update may take several minutes depending on your system.\n")?;

        let manager = match UpdateManager::new() {
            Ok(m) => m,
            Err(e) => {
                self.terminal.write_error(&format!("Update initialization failed: {}", e))?;
                self.terminal.write_info("Troubleshooting tips:")?;
                self.terminal.write("  â€¢ Ensure Prometheus CLI was installed from source (git clone)")?;
                self.terminal.write("  â€¢ Check that git is installed and accessible")?;
                self.terminal.write("  â€¢ Verify the installation directory exists and is readable")?;
                return Ok(());
            }
        };

        if let Err(e) = manager.validate_installation() {
            self.terminal.write_error(&format!("Installation validation failed: {}", e))?;
            self.terminal.write_info("Troubleshooting tips:")?;
            self.terminal.write("  â€¢ Ensure you installed Prometheus CLI using the git-based installer")?;
            self.terminal.write("  â€¢ Manual installations or binary downloads cannot be updated automatically")?;
            self.terminal.write("  â€¢ Consider reinstalling from source: https://github.com/your-repo/prometheus")?;
            return Ok(());
        }

        // Check if updates are available first
        self.terminal.write_info("ðŸ” Checking for available updates...")?;
        match manager.check_for_updates() {
            Ok(UpdateStatus::UpToDate) => {
                self.terminal.write_info("âœ… Your installation is already up to date!")?;
                self.terminal.write("   No update is necessary at this time.")?;
                return Ok(());
            }
            Ok(UpdateStatus::UpdatesAvailable { commits_behind, changes }) => {
                self.terminal.write_info(&format!(
                    "ðŸ“¦ Found {} commit(s) to update. Proceeding with installation...",
                    commits_behind
                ))?;
                
                // Show a preview of changes if available
                if !changes.trim().is_empty() {
                    self.terminal.write("\nðŸ“‹ Changes to be applied:")?;
                    let lines: Vec<&str> = changes.lines().take(3).collect();
                    for line in lines {
                        if !line.trim().is_empty() {
                            self.terminal.write(&format!("   {}", line))?;
                        }
                    }
                    if changes.lines().count() > 3 {
                        self.terminal.write("   ... and more")?;
                    }
                    self.terminal.write("")?;
                }
            }
            Err(e) => {
                self.terminal.write_error(&format!("Failed to check for updates: {}", e))?;
                self.terminal.write_info("Troubleshooting tips:")?;
                self.terminal.write("  â€¢ Check your internet connection")?;
                self.terminal.write("  â€¢ Ensure git credentials are configured if the repository requires authentication")?;
                self.terminal.write("  â€¢ Try running 'git fetch' manually in the installation directory")?;
                return Ok(());
            }
        }

        // Warn about potential interruption
        self.terminal.write_info("âš ï¸  Important: Do not interrupt the update process once it begins.")?;
        self.terminal.write("   Interrupting during binary installation could leave your system in an inconsistent state.\n")?;

        // Perform the update with progress callback
        let result = manager.perform_update(|msg| {
            // Use a new terminal instance for progress messages to avoid borrowing issues
            if let Ok(mut term) = Terminal::new() {
                let _ = term.write_info(msg);
            }
        });

        match result {
            Ok(version) => {
                self.terminal.write("")?;
                self.terminal.write_info("ðŸŽ‰ Update completed successfully!")?;
                self.terminal.write(&format!("   New version: {}", version))?;
                self.terminal.write(&format!("   Installation location: {}", manager.bin_dir().join(manager.binary_name()).display()))?;
                self.terminal.write("")?;
                self.terminal.write_info("ðŸ“ Next steps:")?;
                self.terminal.write("   â€¢ The CLI will now exit to apply the update")?;
                self.terminal.write("   â€¢ Restart the CLI to use the new version")?;
                self.terminal.write("   â€¢ Run '/help' to see any new commands or features")?;
                self.terminal.write("")?;
                self.running = false; // Exit after update
            }
            Err(e) => {
                self.terminal.write("")?;
                self.terminal.write_error(&format!("âŒ Update failed: {}", e))?;
                self.terminal.write_info("ðŸ›¡ï¸  Your existing installation remains unchanged and functional.")?;
                self.terminal.write("")?;
                self.terminal.write_info("ðŸ”§ Troubleshooting options:")?;
                self.terminal.write("   â€¢ Check your internet connection and try again")?;
                self.terminal.write("   â€¢ Ensure you have sufficient disk space")?;
                self.terminal.write("   â€¢ Verify that Rust/Cargo is properly installed")?;
                self.terminal.write("   â€¢ Check the installation directory permissions")?;
                self.terminal.write(&format!("   â€¢ Installation directory: {}", manager.install_dir().display()))?;
                self.terminal.write("   â€¢ Consider running the update with administrator privileges if needed")?;
                self.terminal.write("")?;
                self.terminal.write_info("ðŸ’¡ For persistent issues, consider reinstalling from source.")?;
            }
        }

        Ok(())
    }

    /// Shutdown the application gracefully
    async fn shutdown(&mut self) -> Result<()> {
        // Save final conversation state
        self.conversation_manager
            .save_conversation(&self.conversation)
            .context("Failed to save conversation on shutdown")?;

        // Try to write goodbye message, but don't fail if terminal write fails
        // (this can happen in tests or when output is redirected)
        let _ = self.terminal.write_info("Goodbye!");
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use quickcheck::{QuickCheck, TestResult};
    use std::sync::{Arc, Mutex};
    use uuid::Uuid;

    /// **Feature: cli-version, Property 1: Prompt transmission completeness**
    /// For any non-empty user prompt, when submitted to the CLI, the exact prompt
    /// text should be sent to the configured Ollama backend in the request body.
    /// **Validates: Requirements 1.2**
    /// 
    /// This property tests that the prompt is correctly formatted into a JSON request.
    /// We verify this by checking that the JSON serialization includes the prompt.
    #[test]
    fn prop_prompt_transmission_completeness() {
        fn property(prompt: String) -> TestResult {
            // Filter out empty or whitespace-only prompts
            if prompt.trim().is_empty() {
                return TestResult::discard();
            }

            // Filter out prompts that start with '/' (commands)
            if prompt.starts_with('/') {
                return TestResult::discard();
            }

            // Filter out prompts with control characters that could break JSON
            if prompt.chars().any(|c| c.is_control() && c != '\n' && c != '\t') {
                return TestResult::discard();
            }

            // Limit prompt length
            if prompt.len() > 500 {
                return TestResult::discard();
            }

            // Test that the prompt can be serialized into a JSON request body
            let request_body = serde_json::json!({
                "model": "llama2",
                "prompt": prompt.clone(),
                "stream": true
            });

            // Verify we can serialize it to JSON
            let json_string = match serde_json::to_string(&request_body) {
                Ok(s) => s,
                Err(_) => return TestResult::failed(),
            };

            // Verify we can deserialize it back
            let parsed: serde_json::Value = match serde_json::from_str(&json_string) {
                Ok(v) => v,
                Err(_) => return TestResult::failed(),
            };

            // Verify the prompt field matches exactly (round-trip test)
            match parsed.get("prompt").and_then(|v| v.as_str()) {
                Some(p) if p == prompt => TestResult::passed(),
                _ => TestResult::failed(),
            }
        }

        QuickCheck::new()
            .tests(100)
            .quickcheck(property as fn(String) -> TestResult);
    }

    /// **Feature: cli-version, Property 2: Response display consistency**
    /// For any response received from the backend, the response text should appear
    /// in the terminal output with visual separation markers (such as newlines or formatting).
    /// **Validates: Requirements 1.3**
    /// 
    /// This property tests that responses are correctly captured and displayed.
    /// We verify this by simulating the streaming callback mechanism.
    #[test]
    fn prop_response_display_consistency() {
        fn property(response_text: String) -> TestResult {
            // Filter out empty responses
            if response_text.is_empty() {
                return TestResult::discard();
            }

            // Filter out responses with control characters
            if response_text.chars().any(|c| c.is_control() && c != '\n' && c != '\t') {
                return TestResult::discard();
            }

            // Limit response length
            if response_text.len() > 500 {
                return TestResult::discard();
            }

            // Simulate the streaming callback mechanism
            let output_buffer = Arc::new(Mutex::new(String::new()));
            let output_buffer_clone = Arc::clone(&output_buffer);

            // Simulate receiving the response in chunks
            let chunks: Vec<String> = response_text
                .chars()
                .collect::<Vec<_>>()
                .chunks(10)
                .map(|chunk| chunk.iter().collect())
                .collect();

            // Process each chunk through the callback
            for chunk in chunks {
                let mut buffer = output_buffer_clone.lock().unwrap();
                buffer.push_str(&chunk);
            }

            // Verify the complete response appears in the output
            let output = output_buffer.lock().unwrap();
            if output.contains(&response_text) && *output == response_text {
                TestResult::passed()
            } else {
                TestResult::failed()
            }
        }

        QuickCheck::new()
            .tests(100)
            .quickcheck(property as fn(String) -> TestResult);
    }

    #[tokio::test]
    async fn test_cli_app_creation() {
        let config = AppConfig::default();
        let result = CliApp::new(config, None, None);
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_cli_app_with_url_override() {
        let config = AppConfig::default();
        let custom_url = "http://custom-server:8080".to_string();
        let app = CliApp::new(config, Some(custom_url.clone()), None).unwrap();
        assert_eq!(app.backend_client.base_url(), "http://custom-server:8080");
    }

    #[tokio::test]
    async fn test_cli_app_with_model_override() {
        let config = AppConfig::default();
        let custom_model = "custom-model".to_string();
        let app = CliApp::new(config, None, Some(custom_model.clone())).unwrap();
        assert_eq!(app.model, "custom-model");
    }

    #[tokio::test]
    async fn test_display_welcome() {
        let config = AppConfig::default();
        let mut app = CliApp::new(config, None, None).unwrap();
        let result = app.display_welcome();
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_handle_exit_command() {
        let config = AppConfig::default();
        let mut app = CliApp::new(config, None, None).unwrap();
        assert!(app.running);

        app.handle_command("/exit").await.unwrap();
        assert!(!app.running);
    }

    #[tokio::test]
    async fn test_handle_quit_command() {
        let config = AppConfig::default();
        let mut app = CliApp::new(config, None, None).unwrap();
        assert!(app.running);

        app.handle_command("/quit").await.unwrap();
        assert!(!app.running);
    }

    #[tokio::test]
    async fn test_handle_new_command() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, None, temp_dir.path()).unwrap();
        let original_id = app.conversation.id.clone();

        app.handle_command("/new").await.unwrap();
        assert_ne!(app.conversation.id, original_id);
    }

    #[tokio::test]
    async fn test_handle_help_command() {
        let config = AppConfig::default();
        let mut app = CliApp::new(config, None, None).unwrap();
        let result = app.handle_command("/help").await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_handle_clear_command() {
        let config = AppConfig::default();
        let mut app = CliApp::new(config, None, None).unwrap();
        let result = app.handle_command("/clear").await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_handle_unknown_command() {
        let config = AppConfig::default();
        let mut app = CliApp::new(config, None, None).unwrap();
        let result = app.handle_command("/unknown").await;
        assert!(result.is_ok());
    }

    /// **Feature: cli-version, Property 5: Configuration override precedence**
    /// For any configuration value (URL or model) that exists in both config.toml
    /// and command-line arguments, the command-line argument value should be used
    /// for all operations.
    /// **Validates: Requirements 4.5**
    #[test]
    fn prop_configuration_override_precedence() {
        fn property(config_url: String, cli_url: String, config_model: String, cli_model: String) -> TestResult {
            // Filter out empty strings
            if config_url.trim().is_empty() || cli_url.trim().is_empty() 
                || config_model.trim().is_empty() || cli_model.trim().is_empty() {
                return TestResult::discard();
            }

            // Filter out strings with control characters
            if config_url.chars().any(|c| c.is_control())
                || cli_url.chars().any(|c| c.is_control())
                || config_model.chars().any(|c| c.is_control())
                || cli_model.chars().any(|c| c.is_control()) {
                return TestResult::discard();
            }

            // Limit string lengths
            if config_url.len() > 100 || cli_url.len() > 100 
                || config_model.len() > 50 || cli_model.len() > 50 {
                return TestResult::discard();
            }

            // Ensure URLs and models are different to test override
            if config_url == cli_url || config_model == cli_model {
                return TestResult::discard();
            }

            // Create config with specific values
            let mut config = AppConfig::default();
            config.backend.ollama_url = config_url.clone();

            // Create app with CLI overrides
            let app = match CliApp::new(config, Some(cli_url.clone()), Some(cli_model.clone())) {
                Ok(app) => app,
                Err(_) => return TestResult::discard(),
            };

            // Verify CLI arguments override config values
            if app.backend_url() != cli_url {
                return TestResult::failed();
            }

            if app.model() != cli_model {
                return TestResult::failed();
            }

            TestResult::passed()
        }

        QuickCheck::new()
            .tests(100)
            .quickcheck(property as fn(String, String, String, String) -> TestResult);
    }

    /// **Feature: cli-version, Property 6: Backend URL consistency**
    /// For any prompt sent during a session, all HTTP requests should be directed
    /// to the same backend URL that was configured at startup (either from config or CLI args).
    /// **Validates: Requirements 4.2**
    #[test]
    fn prop_backend_url_consistency() {
        fn property(backend_url: String) -> TestResult {
            // Filter out empty strings
            if backend_url.trim().is_empty() {
                return TestResult::discard();
            }

            // Filter out strings with control characters
            if backend_url.chars().any(|c| c.is_control()) {
                return TestResult::discard();
            }

            // Filter out strings that don't look like URLs
            // Must contain at least one colon and not be just "/"
            if !backend_url.contains(':') || backend_url == "/" {
                return TestResult::discard();
            }

            // Filter out URLs that don't start with http:// or https://
            if !backend_url.starts_with("http://") && !backend_url.starts_with("https://") {
                return TestResult::discard();
            }

            // Filter out URLs with spaces or other problematic characters
            if backend_url.contains(' ') || backend_url.contains('\t') {
                return TestResult::discard();
            }

            // Limit string length
            if backend_url.len() > 100 || backend_url.len() < 3 {
                return TestResult::discard();
            }

            // Create config with default values
            let config = AppConfig::default();

            // Create app with CLI URL override
            let app = match CliApp::new(config, Some(backend_url.clone()), None) {
                Ok(app) => app,
                Err(_) => return TestResult::discard(),
            };

            // BackendClient trims trailing slashes, so we need to compare against the trimmed version
            let expected_url = backend_url.trim_end_matches('/');

            // Verify the backend URL is set correctly
            if app.backend_url() != expected_url {
                return TestResult::failed();
            }

            // Verify the backend client uses the same URL
            if app.backend_client.base_url() != expected_url {
                return TestResult::failed();
            }

            TestResult::passed()
        }

        QuickCheck::new()
            .tests(100)
            .quickcheck(property as fn(String) -> TestResult);
    }

    /// **Feature: cli-version, Property 7: Model parameter consistency**
    /// For any prompt sent during a session, all requests should include the same
    /// model parameter that was configured at startup (either from config or CLI args).
    /// **Validates: Requirements 4.3**
    #[test]
    fn prop_model_parameter_consistency() {
        fn property(model_name: String) -> TestResult {
            // Filter out empty strings
            if model_name.trim().is_empty() {
                return TestResult::discard();
            }

            // Filter out strings with control characters
            if model_name.chars().any(|c| c.is_control()) {
                return TestResult::discard();
            }

            // Limit string length
            if model_name.len() > 50 {
                return TestResult::discard();
            }

            // Create config with default values
            let config = AppConfig::default();

            // Create app with CLI model override
            let app = match CliApp::new(config, None, Some(model_name.clone())) {
                Ok(app) => app,
                Err(_) => return TestResult::discard(),
            };

            // Verify the model is set correctly
            if app.model() != model_name {
                return TestResult::failed();
            }

            // Verify the conversation uses the same model
            if app.conversation.model.as_ref() != Some(&model_name) {
                return TestResult::failed();
            }

            TestResult::passed()
        }

        QuickCheck::new()
            .tests(100)
            .quickcheck(property as fn(String) -> TestResult);
    }

    // Unit tests for configuration scenarios

    /// Test config file loading with valid config
    /// **Validates: Requirements 4.1**
    #[test]
    fn test_config_file_loading() {
        use std::fs;
        use std::path::PathBuf;

        // Create a test config file
        let test_config_path = PathBuf::from("test_config_cli.toml");
        let test_config = r#"
[app]
window_title = "Test App"
window_width = 800.0
window_height = 600.0

[backend]
url = "http://test-server:8080"
ollama_url = "http://test-ollama:11434"
timeout_seconds = 60

[ui]
font_size = 16
max_chat_history = 1000
theme = "Hacker Green"
"#;

        // Write test config
        fs::write(&test_config_path, test_config).expect("Failed to write test config");

        // Load config
        let loaded_config = config::Config::builder()
            .add_source(config::File::from(test_config_path.clone()))
            .build()
            .expect("Failed to build config")
            .try_deserialize::<AppConfig>()
            .expect("Failed to deserialize config");

        // Clean up
        fs::remove_file(&test_config_path).ok();

        // Verify config values
        assert_eq!(loaded_config.backend.ollama_url, "http://test-ollama:11434");
        assert_eq!(loaded_config.backend.timeout_seconds, 60);
    }

    /// Test default value fallback when config is missing
    /// **Validates: Requirements 4.4**
    #[tokio::test]
    async fn test_default_value_fallback() {
        // Create app with default config (simulating missing config file)
        let config = AppConfig::default();
        let app = CliApp::new(config.clone(), None, None).unwrap();

        // Verify default values are used
        assert_eq!(app.backend_url(), config.backend.ollama_url);
        assert_eq!(app.model(), "llama2");
    }

    /// Test CLI argument parsing and override
    /// **Validates: Requirements 4.5**
    #[tokio::test]
    async fn test_cli_argument_override() {
        let config = AppConfig::default();
        let cli_url = "http://custom-server:9999".to_string();
        let cli_model = "custom-model".to_string();

        let app = CliApp::new(config, Some(cli_url.clone()), Some(cli_model.clone())).unwrap();

        // Verify CLI arguments override config values
        assert_eq!(app.backend_url(), cli_url);
        assert_eq!(app.model(), cli_model);
    }

    /// Test invalid config handling (missing required fields)
    /// **Validates: Requirements 4.4**
    #[test]
    fn test_invalid_config_handling() {
        use std::fs;
        use std::path::PathBuf;

        // Create an invalid config file (missing required fields)
        let test_config_path = PathBuf::from("test_invalid_config.toml");
        let test_config = r#"
[app]
window_title = "Test App"
# Missing other required fields
"#;

        // Write test config
        fs::write(&test_config_path, test_config).expect("Failed to write test config");

        // Try to load config - should fail
        let result = config::Config::builder()
            .add_source(config::File::from(test_config_path.clone()))
            .build()
            .and_then(|cfg| cfg.try_deserialize::<AppConfig>());

        // Clean up
        fs::remove_file(&test_config_path).ok();

        // Config loading should fail, and the app should fall back to defaults
        assert!(result.is_err());

        // In the actual app, this is handled by using AppConfig::default()
        let default_config = AppConfig::default();
        let app = CliApp::new(default_config, None, None);
        assert!(app.is_ok());
    }

    /// Test that config values are used when no CLI overrides are provided
    /// **Validates: Requirements 4.2, 4.3**
    #[tokio::test]
    async fn test_config_values_without_overrides() {
        let mut config = AppConfig::default();
        config.backend.ollama_url = "http://config-server:7777".to_string();

        let app = CliApp::new(config.clone(), None, None).unwrap();

        // Verify config values are used
        assert_eq!(app.backend_url(), config.backend.ollama_url);
        assert_eq!(app.model(), "llama2"); // Default model
    }

    /// Test partial CLI overrides (only URL)
    /// **Validates: Requirements 4.5**
    #[tokio::test]
    async fn test_partial_cli_override_url_only() {
        let mut config = AppConfig::default();
        config.backend.ollama_url = "http://config-server:7777".to_string();

        let cli_url = "http://cli-server:8888".to_string();
        let app = CliApp::new(config, Some(cli_url.clone()), None).unwrap();

        // Verify URL is overridden but model uses default
        assert_eq!(app.backend_url(), cli_url);
        assert_eq!(app.model(), "llama2");
    }

    /// Test partial CLI overrides (only model)
    /// **Validates: Requirements 4.5**
    #[tokio::test]
    async fn test_partial_cli_override_model_only() {
        let mut config = AppConfig::default();
        config.backend.ollama_url = "http://config-server:7777".to_string();

        let cli_model = "cli-model".to_string();
        let app = CliApp::new(config.clone(), None, Some(cli_model.clone())).unwrap();

        // Verify model is overridden but URL uses config
        assert_eq!(app.backend_url(), config.backend.ollama_url);
        assert_eq!(app.model(), cli_model);
    }

    /// **Feature: cli-version, Property 4: Conversation persistence round-trip**
    /// For any message added to a conversation (user prompt or AI response), after
    /// persisting to disk and reloading the conversation, the message should be
    /// present with identical content and timestamp.
    /// **Validates: Requirements 3.1, 3.2, 3.3**
    #[test]
    fn prop_conversation_persistence_round_trip() {
        fn property(user_content: String, ai_content: String) -> TestResult {
            // Filter out empty messages
            if user_content.trim().is_empty() || ai_content.trim().is_empty() {
                return TestResult::discard();
            }

            // Filter out messages with control characters (except newlines and tabs)
            if user_content.chars().any(|c| c.is_control() && c != '\n' && c != '\t')
                || ai_content.chars().any(|c| c.is_control() && c != '\n' && c != '\t') {
                return TestResult::discard();
            }

            // Limit message length to avoid excessive test data
            if user_content.len() > 500 || ai_content.len() > 500 {
                return TestResult::discard();
            }

            // Create a conversation manager
            let manager = ConversationManager::new();

            // Create a new conversation with a unique ID for this test
            let mut conversation = Conversation::new(
                format!("Test Conversation {}", Uuid::new_v4()),
                Some("test-model".to_string())
            );

            // Add user message
            let user_message = ChatMessage::new("user".to_string(), user_content.clone());
            let user_timestamp = user_message.timestamp.clone();
            conversation.add_message(user_message);

            // Add AI response
            let ai_message = ChatMessage::new("assistant".to_string(), ai_content.clone());
            let ai_timestamp = ai_message.timestamp.clone();
            conversation.add_message(ai_message);

            // Save the conversation
            if let Err(_) = manager.save_conversation(&conversation) {
                return TestResult::discard();
            }

            // Load the conversation back
            let loaded_conversation = match manager.load_conversation(&conversation.id) {
                Ok(conv) => conv,
                Err(_) => {
                    // Clean up
                    manager.delete_conversation(&conversation.id).ok();
                    return TestResult::failed();
                }
            };

            // Clean up
            manager.delete_conversation(&conversation.id).ok();

            // Verify the conversation has the same ID
            if loaded_conversation.id != conversation.id {
                return TestResult::failed();
            }

            // Verify we have exactly 2 messages
            if loaded_conversation.messages.len() != 2 {
                return TestResult::failed();
            }

            // Verify user message content and timestamp
            let loaded_user_msg = &loaded_conversation.messages[0];
            if loaded_user_msg.role != "user" {
                return TestResult::failed();
            }
            if loaded_user_msg.content != user_content {
                return TestResult::failed();
            }
            if loaded_user_msg.timestamp != user_timestamp {
                return TestResult::failed();
            }

            // Verify AI message content and timestamp
            let loaded_ai_msg = &loaded_conversation.messages[1];
            if loaded_ai_msg.role != "assistant" {
                return TestResult::failed();
            }
            if loaded_ai_msg.content != ai_content {
                return TestResult::failed();
            }
            if loaded_ai_msg.timestamp != ai_timestamp {
                return TestResult::failed();
            }

            TestResult::passed()
        }

        QuickCheck::new()
            .tests(100)
            .quickcheck(property as fn(String, String) -> TestResult);
    }

    // Unit tests for conversation lifecycle

    /// Test conversation creation with timestamp name
    /// **Validates: Requirements 3.4**
    #[tokio::test]
    async fn test_conversation_creation_with_timestamp_name() {
        let config = AppConfig::default();
        let app = CliApp::new(config, None, Some("test-model".to_string())).unwrap();

        // Verify conversation was created
        assert!(!app.conversation.id.is_empty());
        assert!(!app.conversation.name.is_empty());
        
        // Verify name contains "Chat" prefix (timestamp format)
        assert!(app.conversation.name.starts_with("Chat "));
        
        // Verify model is set
        assert_eq!(app.conversation.model, Some("test-model".to_string()));
        
        // Verify conversation starts empty
        assert_eq!(app.conversation.messages.len(), 0);
        
        // Verify timestamps are set
        assert!(!app.conversation.created_at.is_empty());
        assert!(!app.conversation.updated_at.is_empty());
    }

    /// Test message addition to conversation
    /// **Validates: Requirements 3.1, 3.2**
    #[tokio::test]
    async fn test_message_addition() {
        let config = AppConfig::default();
        let mut app = CliApp::new(config, None, None).unwrap();

        // Initially empty
        assert_eq!(app.conversation.messages.len(), 0);

        // Add a user message
        let user_msg = ChatMessage::new("user".to_string(), "Hello".to_string());
        let user_timestamp = user_msg.timestamp.clone();
        app.conversation.add_message(user_msg);

        // Verify message was added
        assert_eq!(app.conversation.messages.len(), 1);
        assert_eq!(app.conversation.messages[0].role, "user");
        assert_eq!(app.conversation.messages[0].content, "Hello");
        assert_eq!(app.conversation.messages[0].timestamp, user_timestamp);

        // Add an AI response
        let ai_msg = ChatMessage::new("assistant".to_string(), "Hi there!".to_string());
        let ai_timestamp = ai_msg.timestamp.clone();
        app.conversation.add_message(ai_msg);

        // Verify both messages are present
        assert_eq!(app.conversation.messages.len(), 2);
        assert_eq!(app.conversation.messages[1].role, "assistant");
        assert_eq!(app.conversation.messages[1].content, "Hi there!");
        assert_eq!(app.conversation.messages[1].timestamp, ai_timestamp);
    }

    /// Test conversation saving on exit
    /// **Validates: Requirements 3.5**
    #[tokio::test]
    async fn test_conversation_saving_on_exit() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();

        // Add some messages
        app.conversation.add_message(ChatMessage::new("user".to_string(), "Test message".to_string()));
        app.conversation.add_message(ChatMessage::new("assistant".to_string(), "Test response".to_string()));

        let conversation_id = app.conversation.id.clone();

        // Call shutdown (which saves the conversation)
        let result = app.shutdown().await;
        assert!(result.is_ok());

        // Verify conversation was saved by loading it back
        let manager = ConversationManager::with_directory(temp_dir.path());
        let loaded = manager.load_conversation(&conversation_id);
        assert!(loaded.is_ok());

        let loaded_conv = loaded.unwrap();
        assert_eq!(loaded_conv.id, conversation_id);
        assert_eq!(loaded_conv.messages.len(), 2);
        assert_eq!(loaded_conv.messages[0].content, "Test message");
        assert_eq!(loaded_conv.messages[1].content, "Test response");

        // Clean up
        manager.delete_conversation(&conversation_id).ok();
    }

    /// Test automatic conversation persistence after message addition
    /// **Validates: Requirements 3.3**
    #[tokio::test]
    async fn test_automatic_conversation_persistence() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();

        // Add a message
        app.conversation.add_message(ChatMessage::new("user".to_string(), "Persist me".to_string()));

        let conversation_id = app.conversation.id.clone();

        // Manually save (simulating what happens in handle_prompt)
        let result = app.conversation_manager.save_conversation(&app.conversation);
        assert!(result.is_ok());

        // Verify it was persisted by loading it back
        let loaded = app.conversation_manager.load_conversation(&conversation_id);
        assert!(loaded.is_ok());

        let loaded_conv = loaded.unwrap();
        assert_eq!(loaded_conv.messages.len(), 1);
        assert_eq!(loaded_conv.messages[0].content, "Persist me");

        // Clean up
        app.conversation_manager.delete_conversation(&conversation_id).ok();
    }

    /// Test conversation persistence with multiple messages
    /// **Validates: Requirements 3.1, 3.2, 3.3**
    #[tokio::test]
    async fn test_conversation_persistence_multiple_messages() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();

        let conversation_id = app.conversation.id.clone();

        // Add multiple messages
        for i in 0..5 {
            app.conversation.add_message(ChatMessage::new(
                "user".to_string(),
                format!("Message {}", i)
            ));
            app.conversation.add_message(ChatMessage::new(
                "assistant".to_string(),
                format!("Response {}", i)
            ));
        }

        // Save conversation
        app.conversation_manager.save_conversation(&app.conversation).unwrap();

        // Load it back
        let loaded = app.conversation_manager.load_conversation(&conversation_id).unwrap();

        // Verify all messages are present
        assert_eq!(loaded.messages.len(), 10);
        for i in 0..5 {
            assert_eq!(loaded.messages[i * 2].content, format!("Message {}", i));
            assert_eq!(loaded.messages[i * 2 + 1].content, format!("Response {}", i));
        }

        // Clean up
        app.conversation_manager.delete_conversation(&conversation_id).ok();
    }

    /// Test that timestamps are preserved during persistence
    /// **Validates: Requirements 3.1, 3.2**
    #[tokio::test]
    async fn test_timestamp_preservation() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, None, temp_dir.path()).unwrap();

        let conversation_id = app.conversation.id.clone();

        // Add a message with a specific timestamp
        let msg = ChatMessage::new("user".to_string(), "Timestamped message".to_string());
        let original_timestamp = msg.timestamp.clone();
        app.conversation.add_message(msg);

        // Save and reload
        app.conversation_manager.save_conversation(&app.conversation).unwrap();
        let loaded = app.conversation_manager.load_conversation(&conversation_id).unwrap();

        // Verify timestamp is preserved exactly
        assert_eq!(loaded.messages[0].timestamp, original_timestamp);

        // Clean up
        app.conversation_manager.delete_conversation(&conversation_id).ok();
    }

    // Signal handling tests

    /// Test SIGINT at prompt saves conversation and exits
    /// **Validates: Requirements 9.5, 10.5**
    #[tokio::test]
    async fn test_sigint_at_prompt() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();
        
        // Add a message to the conversation
        app.conversation.add_message(ChatMessage::new("user".to_string(), "Test message".to_string()));
        
        let conversation_id = app.conversation.id.clone();
        
        // Simulate SIGINT by calling shutdown directly
        // In a real scenario, the signal would be caught in the run loop
        let result = app.shutdown().await;
        if let Err(e) = &result {
            eprintln!("Shutdown error: {:?}", e);
        }
        assert!(result.is_ok(), "Shutdown failed: {:?}", result.err());
        
        // Verify conversation was saved
        let manager = ConversationManager::with_directory(temp_dir.path());
        let loaded = manager.load_conversation(&conversation_id);
        assert!(loaded.is_ok());
        
        let loaded_conv = loaded.unwrap();
        assert_eq!(loaded_conv.messages.len(), 1);
        assert_eq!(loaded_conv.messages[0].content, "Test message");
        
        // Clean up
        manager.delete_conversation(&conversation_id).ok();
    }

    /// Test SIGTERM handling saves conversation and exits
    /// **Validates: Requirements 10.3**
    #[tokio::test]
    async fn test_sigterm_handling() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();
        
        // Add messages to the conversation
        app.conversation.add_message(ChatMessage::new("user".to_string(), "Message 1".to_string()));
        app.conversation.add_message(ChatMessage::new("assistant".to_string(), "Response 1".to_string()));
        
        let conversation_id = app.conversation.id.clone();
        
        // Simulate SIGTERM by calling shutdown
        let result = app.shutdown().await;
        assert!(result.is_ok());
        
        // Verify conversation was saved with all messages
        let manager = ConversationManager::with_directory(temp_dir.path());
        let loaded = manager.load_conversation(&conversation_id);
        assert!(loaded.is_ok());
        
        let loaded_conv = loaded.unwrap();
        assert_eq!(loaded_conv.messages.len(), 2);
        assert_eq!(loaded_conv.messages[0].content, "Message 1");
        assert_eq!(loaded_conv.messages[1].content, "Response 1");
        
        // Clean up
        manager.delete_conversation(&conversation_id).ok();
    }

    /// Test partial response saving when interrupted
    /// **Validates: Requirements 10.2**
    #[tokio::test]
    async fn test_partial_response_saving() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();
        
        let conversation_id = app.conversation.id.clone();
        
        // Add user message
        app.conversation.add_message(ChatMessage::new("user".to_string(), "Test prompt".to_string()));
        
        // Simulate partial response (as would happen during interruption)
        let partial_response = "This is a partial response that was interrupted...";
        app.conversation.add_message(ChatMessage::new("assistant".to_string(), partial_response.to_string()));
        
        // Save conversation
        app.conversation_manager.save_conversation(&app.conversation).unwrap();
        
        // Verify partial response was saved
        let loaded = app.conversation_manager.load_conversation(&conversation_id).unwrap();
        assert_eq!(loaded.messages.len(), 2);
        assert_eq!(loaded.messages[0].content, "Test prompt");
        assert_eq!(loaded.messages[1].content, partial_response);
        assert_eq!(loaded.messages[1].role, "assistant");
        
        // Clean up
        app.conversation_manager.delete_conversation(&conversation_id).ok();
    }

    /// Test that conversation is saved even with empty partial response
    /// **Validates: Requirements 10.2**
    #[tokio::test]
    async fn test_empty_partial_response_handling() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();
        
        let conversation_id = app.conversation.id.clone();
        
        // Add user message
        app.conversation.add_message(ChatMessage::new("user".to_string(), "Test prompt".to_string()));
        
        // Save conversation (simulating interruption before any response)
        app.conversation_manager.save_conversation(&app.conversation).unwrap();
        
        // Verify conversation was saved with just the user message
        let loaded = app.conversation_manager.load_conversation(&conversation_id).unwrap();
        assert_eq!(loaded.messages.len(), 1);
        assert_eq!(loaded.messages[0].content, "Test prompt");
        assert_eq!(loaded.messages[0].role, "user");
        
        // Clean up
        app.conversation_manager.delete_conversation(&conversation_id).ok();
    }

    /// Test graceful shutdown with multiple messages
    /// **Validates: Requirements 9.5**
    #[tokio::test]
    async fn test_graceful_shutdown_multiple_messages() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();
        
        let conversation_id = app.conversation.id.clone();
        
        // Add multiple messages
        for i in 0..5 {
            app.conversation.add_message(ChatMessage::new("user".to_string(), format!("User message {}", i)));
            app.conversation.add_message(ChatMessage::new("assistant".to_string(), format!("AI response {}", i)));
        }
        
        // Shutdown gracefully
        let result = app.shutdown().await;
        assert!(result.is_ok());
        
        // Verify all messages were saved
        let manager = ConversationManager::with_directory(temp_dir.path());
        let loaded = manager.load_conversation(&conversation_id).unwrap();
        assert_eq!(loaded.messages.len(), 10);
        
        // Verify message order and content
        for i in 0..5 {
            assert_eq!(loaded.messages[i * 2].content, format!("User message {}", i));
            assert_eq!(loaded.messages[i * 2 + 1].content, format!("AI response {}", i));
        }
        
        // Clean up
        manager.delete_conversation(&conversation_id).ok();
    }

    /// Test that shutdown is idempotent (can be called multiple times)
    /// **Validates: Requirements 9.5**
    #[tokio::test]
    async fn test_shutdown_idempotent() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();
        
        let conversation_id = app.conversation.id.clone();
        
        // Add a message
        app.conversation.add_message(ChatMessage::new("user".to_string(), "Test".to_string()));
        
        // Call shutdown once
        let result1 = app.shutdown().await;
        assert!(result1.is_ok(), "First shutdown failed: {:?}", result1.err());
        
        // Calling shutdown again should still work (even if terminal write fails, conversation save should succeed)
        // We just verify the conversation was saved correctly
        let manager = ConversationManager::with_directory(temp_dir.path());
        let loaded = manager.load_conversation(&conversation_id).unwrap();
        assert_eq!(loaded.messages.len(), 1);
        
        // Clean up
        manager.delete_conversation(&conversation_id).ok();
    }

    /// Test conversation persistence on shutdown with no messages
    /// **Validates: Requirements 9.5**
    #[tokio::test]
    async fn test_shutdown_empty_conversation() {
        let temp_dir = tempfile::tempdir().unwrap();
        let config = AppConfig::default();
        let mut app = CliApp::new_with_temp_dir(config, None, Some("test-model".to_string()), temp_dir.path()).unwrap();
        
        let conversation_id = app.conversation.id.clone();
        
        // Shutdown without adding any messages
        let result = app.shutdown().await;
        assert!(result.is_ok());
        
        // Verify empty conversation was saved
        let manager = ConversationManager::with_directory(temp_dir.path());
        let loaded = manager.load_conversation(&conversation_id).unwrap();
        assert_eq!(loaded.messages.len(), 0);
        assert_eq!(loaded.id, conversation_id);
        
        // Clean up
        manager.delete_conversation(&conversation_id).ok();
    }
}
